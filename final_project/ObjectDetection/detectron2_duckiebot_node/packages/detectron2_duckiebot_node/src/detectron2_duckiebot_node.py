#!/usr/bin/env python3
import rospy
from duckietown.dtros import DTROS, TopicType, NodeType
from sensor_msgs.msg import CompressedImage
from std_msgs.msg import String
import rospkg

import numpy as np
import sys, os, distutils.core
import math
import cv2
import torch, detectron2
from detectron2.utils.logger import setup_logger
import json
from detectron2.utils.visualizer import ColorMode

# import some common detectron2 utilities
from detectron2 import model_zoo
from detectron2.engine import DefaultPredictor
from detectron2.config import get_cfg
from detectron2.utils.visualizer import Visualizer
from detectron2.data import MetadataCatalog, DatasetCatalog
from detectron2.structures import BoxMode
from detectron2.engine import DefaultTrainer
import threading

"""Detectron2-Duckiebot.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11jrZvjetAeoH7LiuMAOxTGTf1TEKwStf
"""

rospack = rospkg.RosPack()
OUTPUT_MODEL_PATH = rospack.get_path("detectron2_duckiebot_node") + "/src/model_final.pth" # "/content/drive/MyDrive/CMPUT412/Project/model_final.pth"
BAG_FILE_PATH = "/content/drive/MyDrive/CMPUT412/Project/more_dataset_gen.bag"  # a bag file not in training set, for testing

TIME_CUTOFF_MIN = 0 # 1681175162 #1681175159791011507
TIME_CUTOFF_MAX = math.inf # 1680653588


HOST_NAME = os.environ["VEHICLE_NAME"]


class Detectron2_Duckiebot(DTROS):

    def __init__(self,node_name):

        super(Detectron2_Duckiebot, self).__init__(node_name=node_name, node_type=NodeType.GENERIC)
        
        self.lock = threading.Lock()

        self.veh = str(os.environ["VEHICLE_NAME"])
        self.seq = 0 

        self.image = None
        self.rospack = rospkg.RosPack()
        self.path = self.rospack.get_path("detectron2_duckiebot_node")
        """Detection Network variables"""

        TORCH_VERSION = ".".join(torch.__version__.split(".")[:2])
        #CUDA_VERSION = torch.__version__.split("+")[-1]
        #print("torch: ", TORCH_VERSION, "; cuda: ", CUDA_VERSION)
        print("detectron2:", detectron2.__version__)

        self.sub = rospy.Subscriber(f'/{HOST_NAME}/camera_node/image/compressed', CompressedImage, self.callback)
        self.pub = rospy.Publisher(f'/{HOST_NAME}/detectron2_duckiebot/detected_objects', String, queue_size=1)
        self.img_pub = rospy.Publisher(f'/{HOST_NAME}/camera_node/image/object_detection/compressed', CompressedImage, queue_size=1)

        # Some basic setup:
        # Setup detectron2 logger
        setup_logger()  

        self.cfg = get_cfg()

        DatasetCatalog.clear()
        for d in ["train"]:
            MetadataCatalog.get("duckie_" + d).set(thing_classes=["duck", "duckiebot"])
        self.duckie_metadata = MetadataCatalog.get("duckie_train")

    def callback(self, msg):
        # how to decode compressed image
        # reference: http://wiki.ros.org/rospy_tutorials/Tutorials/WritingImagePublisherSubscriber
        compressed_image = np.frombuffer(msg.data, np.uint8)
        im = cv2.imdecode(compressed_image, cv2.IMREAD_COLOR)
        self.lock.acquire()
        self.image = im
        self.lock.release()

    def send_compressed(self,pub, seq, frame_id, im):
        msg = CompressedImage()
        msg.header.seq = seq
        msg.header.stamp = rospy.Time.now()
        msg.header.frame_id = frame_id
        msg.format = 'jpeg'
        ret, buffer = cv2.imencode('.jpg', im)
        if not ret:
            print('failed to encode image!')
        else:
            msg.data = np.array(buffer).tostring()
            pub.publish(msg)
        return ret

    def fine_tune_model(self):

        """

        Now, let's fine-tune a COCO-pretrained R50-FPN Mask R-CNN model on the balloon dataset. It takes ~2 minutes to train 300 iterations on a P100 GPU.

        """

        self.cfg.merge_from_file(model_zoo.get_config_file("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml"))
        self.cfg.DATASETS.TRAIN = ("duckie_train",)
        self.cfg.MODEL.DEVICE ="cpu"
        self.cfg.DATASETS.TEST = ()
        self.cfg.DATALOADER.NUM_WORKERS = 2
        self.cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url("COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml")  # Let training initialize from model zoo
        self.cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real "batch size" commonly known to deep learning people
        self.cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR
        self.cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for this toy dataset; you will need to train longer for a practical dataset
        self.cfg.SOLVER.STEPS = []        # do not decay learning rate
        self.cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128   # The "RoIHead batch size". 128 is faster, and good enough for this toy dataset (default: 512)
        self.cfg.MODEL.ROI_HEADS.NUM_CLASSES = 2  # only has one class (ballon). (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)
        # NOTE: this config means the number of classes, but a few popular unofficial tutorials incorrect uses num_classes+1 here.  
        
    def inference(self):

        """## Inference & evaluation using the trained model
        """
        # Inference should use the config with parameters that are used in training
        # cfg now already contains everything we've set previously. We changed it a little bit for inference:
        self.cfg.MODEL.WEIGHTS = OUTPUT_MODEL_PATH # path to the model we just trained
        self.cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.8   # set a custom testing threshold
        self.predictor = DefaultPredictor(self.cfg)

    def publish_detections(self):

        self.lock.acquire()
        im = self.image
        self.lock.release()
        outputs = self.predictor(im)
        v = Visualizer(im[:, :, ::-1],
                    metadata=self.duckie_metadata, 
                    scale=0.5, 
                    instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models
        )
        print(outputs)
        out = v.draw_instance_predictions(outputs["instances"].to("cpu"))

        ret = self.send_compressed(self.img_pub, self.seq, f'{HOST_NAME}/camera_optical_frame', out.get_image()[:, :, ::-1])
        if ret:
            self.seq += 1

        pred_boxes = outputs["instances"].get("pred_boxes").tensor
        scores = outputs["instances"].get("scores")
        pred_classes = outputs["instances"].get("pred_classes")

        msg = json.dumps({'class':pred_classes.tolist(),'pred_boxes': pred_boxes.tolist(), 'scores': scores.tolist()})
        self.pub(String(msg))

if __name__ == '__main__':
    detect_node = Detectron2_Duckiebot("detectron2_duckiebot")

    detect_node.fine_tune_model()

    detect_node.inference()

    while True:
        detect_node.publish_detections()

# image_count = 0
# for topic, msg, t in bag.read_messages(topics=[f'/{HOST_NAME}/camera_node/image/compressed']):
#     if t.secs < TIME_CUTOFF_MIN:
#         continue
#     elif t.secs > TIME_CUTOFF_MAX:
#         break
    
#     image_count += 1

#     if image_count % 20 != 0:
#         continue
#     im = cv2.imdecode(np.frombuffer(msg.data, np.uint8), cv2.IMREAD_COLOR)

    
    
#     if image_count >= 1800:
#         print(t)
#         break
